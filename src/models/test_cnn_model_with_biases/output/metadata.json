{
  "original_model": "models/test_cnn_model_with_biases/test_cnn_model.pth",
  "model_type": "ModelType.HYBRID",
  "total_parameters": 1312042,
  "slicing_strategy": "transitions",
  "segments": [
    {
      "index": 0,
      "type": "conv",
      "segment_name": "conv_0",
      "filename": "conv_0.pt",
      "path": "models/test_cnn_model_with_biases/output/conv_0.pt",
      "layer_count": 4,
      "parameters": 97440,
      "layers": [
        {
          "name": "conv1",
          "parameters": {
            "weight": {
              "shape": [
                16,
                3,
                3,
                3
              ],
              "size": 432
            },
            "bias": {
              "shape": [
                16
              ],
              "size": 16
            }
          },
          "shape": [
            16,
            3,
            3,
            3
          ],
          "type": "conv",
          "size": 448,
          "in_channels": 3,
          "out_channels": 16,
          "kernel_size": [
            3,
            3
          ],
          "activation": "ReLU"
        },
        {
          "name": "conv3",
          "parameters": {
            "weight": {
              "shape": [
                32,
                16,
                3,
                3
              ],
              "size": 4608
            },
            "bias": {
              "shape": [
                32
              ],
              "size": 32
            }
          },
          "shape": [
            32,
            16,
            3,
            3
          ],
          "type": "conv",
          "size": 4640,
          "in_channels": 16,
          "out_channels": 32,
          "kernel_size": [
            3,
            3
          ],
          "activation": "ReLU"
        },
        {
          "name": "conv5",
          "parameters": {
            "weight": {
              "shape": [
                64,
                32,
                3,
                3
              ],
              "size": 18432
            },
            "bias": {
              "shape": [
                64
              ],
              "size": 64
            }
          },
          "shape": [
            64,
            32,
            3,
            3
          ],
          "type": "conv",
          "size": 18496,
          "in_channels": 32,
          "out_channels": 64,
          "kernel_size": [
            3,
            3
          ],
          "activation": "ReLU"
        },
        {
          "name": "conv7",
          "parameters": {
            "weight": {
              "shape": [
                128,
                64,
                3,
                3
              ],
              "size": 73728
            },
            "bias": {
              "shape": [
                128
              ],
              "size": 128
            }
          },
          "shape": [
            128,
            64,
            3,
            3
          ],
          "type": "conv",
          "size": 73856,
          "in_channels": 64,
          "out_channels": 128,
          "kernel_size": [
            3,
            3
          ],
          "activation": "ReLU"
        }
      ],
      "in_features": 3,
      "out_features": 128,
      "activation": "ReLU",
      "class_file": "conv_0_segment.py",
      "class_name": "Conv_0Segment"
    },
    {
      "index": 1,
      "type": "fc",
      "segment_name": "fc_1",
      "filename": "fc_1.pt",
      "path": "models/test_cnn_model_with_biases/output/fc_1.pt",
      "layer_count": 4,
      "parameters": 1214602,
      "layers": [
        {
          "name": "fc8",
          "parameters": {
            "weight": {
              "shape": [
                512,
                2048
              ],
              "size": 1048576
            },
            "bias": {
              "shape": [
                512
              ],
              "size": 512
            }
          },
          "shape": [
            512,
            2048
          ],
          "type": "linear",
          "size": 1049088,
          "in_features": 2048,
          "out_features": 512,
          "activation": "ReLU"
        },
        {
          "name": "fc9",
          "parameters": {
            "weight": {
              "shape": [
                256,
                512
              ],
              "size": 131072
            },
            "bias": {
              "shape": [
                256
              ],
              "size": 256
            }
          },
          "shape": [
            256,
            512
          ],
          "type": "linear",
          "size": 131328,
          "in_features": 512,
          "out_features": 256,
          "activation": "ReLU"
        },
        {
          "name": "fc10",
          "parameters": {
            "weight": {
              "shape": [
                128,
                256
              ],
              "size": 32768
            },
            "bias": {
              "shape": [
                128
              ],
              "size": 128
            }
          },
          "shape": [
            128,
            256
          ],
          "type": "linear",
          "size": 32896,
          "in_features": 256,
          "out_features": 128,
          "activation": "ReLU"
        },
        {
          "name": "fc11",
          "parameters": {
            "weight": {
              "shape": [
                10,
                128
              ],
              "size": 1280
            },
            "bias": {
              "shape": [
                10
              ],
              "size": 10
            }
          },
          "shape": [
            10,
            128
          ],
          "type": "linear",
          "size": 1290,
          "in_features": 128,
          "out_features": 10,
          "activation": "Softmax"
        }
      ],
      "activation": "Softmax",
      "input_reshape": {
        "type": "flatten",
        "from_shape": [
          null,
          128,
          4,
          4
        ],
        "to_shape": [
          null,
          2048
        ]
      },
      "class_file": "fc_1_segment.py",
      "class_name": "Fc_1Segment"
    }
  ],
  "slice_points": [
    3
  ]
}